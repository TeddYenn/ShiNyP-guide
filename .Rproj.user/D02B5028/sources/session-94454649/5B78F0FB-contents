---
title: "GWAS Tutorial"
subtitle: "For Anaerobic Germination in Rice"
author: "Yen-Hsiang (Teddy) Huang"
date: "`r Sys.Date()`"
knit: "bookdown::render_book"
site: bookdown::bookdown_site
output: bookdown::bs4_book
documentclass: book
bibliography: [book.bib]
biblio-style: apalike
link-citations: true
links-as-notes: true
colorlinks: true
github-repo: dgrtwo/tidy-text-mining
cover-image: images/cover.png
url: https://www.tidytextmining.com/
description: "A guide to GWAS analysis in rice, using the R and PLINK programs"
---

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'rmallet'
), 'packages.bib')
```

# Welcome to GWAS Tutorial {#sec-welcome-to-gwas-tutorial .unnumbered}

This is the [website](http://tidytextmining.com/) for **GWAS analysis
with R and PLINK programs**.

This work by **Yen-Hsiang (Teddy) Huang** is licensed under a
<a rel="license" href="https://www.gnu.org/licenses/gpl-3.0.html.en">GNU
General Public License</a>.

<a href="https://www.gnu.org/licenses/gpl-3.0.html.en">
![](images/clipboard-3960043298.png)</a>

```{=html}
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68765210-2', 'auto');
  ga('send', 'pageview');

</script>
```
# Preface {.unnumbered}

This GitHub page provides a hands-on tutorial on genome-wide association
studies (GWAS) as part of Teddy's and Lumi's research program at Texas
A&M University under the supervision of Dr. Endang Septiningsih and Dr.
Michael Thomson.

The tutorial focuses on standard workflow, codes, and resources needed
to perform a GWAS in rice and is divided into seven sections. For
absolute beginners, weâ€™ve also included an introductory section on
[R](https://www.r-project.org/),
[RStudio](https://posit.co/download/rstudio-desktop/), and
[PLINK](https://www.cog-genomics.org/plink/).

If you have any questions or suggestions, feel free to reach out via
email at [teddy7305\@gmail.com](mailto:teddy7305@gmail.com){.email}
(Teddy Huang) and
[eseptiningsih\@tamu.edu](mailto:eseptiningsih@tamu.edu) (Dr.
Septiningsih).

## Outline {.unnumbered}

We begin by processing genotypic and phenotypic datasets, followed by
conducting GWAS and post-GWAS analyses, and conclude with findings and
interpretations of the results.

-   **Chapter** \@ref(sec-genotype-data) outlines the tidy text format
    and the `unnest_tokens()` function. It also introduces the
    gutenbergr and janeaustenr packages, which provide useful literary
    text datasets that we'll use throughout this book.
-   **Chapter** \@ref(sentiment) shows how to perform sentiment analysis
    on a tidy text dataset, using the `sentiments` dataset from tidytext
    and `inner_join()` from dplyr.
-   **Chapter** \@ref(tfidf) describes the tf-idf statistic (term
    frequency times inverse document frequency), a quantity used for
    identifying terms that are especially important to a particular
    document.
-   **Chapter** \@ref(ngrams) introduces n-grams and how to analyze word
    networks in text using the widyr and ggraph packages.

Text won't be tidy at all stages of an analysis, and it is important to
be able to convert back and forth between tidy and non-tidy formats.

-   **Chapter** \@ref(dtm) introduces methods for tidying document-term
    matrices and corpus objects from the tm and quanteda packages, as
    well as for casting tidy text datasets into those formats.
-   **Chapter** \@ref(topicmodeling) explores the concept of topic
    modeling, and uses the `tidy()` method to interpret and visualize
    the output of the topicmodels package.

We conclude with several case studies that bring together multiple tidy
text mining approaches we've learned.

-   **Chapter** \@ref(twitter) demonstrates an application of a tidy
    text analysis by analyzing the authors' own Twitter archives. How do
    Dave's and Julia's tweeting habits compare?
-   **Chapter** \@ref(nasa) explores metadata from over 32,000 NASA
    datasets (available in JSON) by looking at how keywords from the
    datasets are connected to title and description fields.
-   **Chapter** \@ref(usenet) analyzes a dataset of Usenet messages from
    a diverse set of newsgroups (focused on topics like politics,
    hockey, technology, atheism, and more) to understand patterns across
    the groups.

## About this book {.unnumbered}

This book is focused on practical software examples and data
explorations. There are few equations, but a great deal of code. We
especially focus on generating real insights from the literature, news,
and social media that we analyze.

We don't assume any previous knowledge of text mining. Professional
linguists and text analysts will likely find our examples elementary,
though we are confident they can build on the framework for their own
analyses.

We do assume that the reader is at least slightly familiar with dplyr,
ggplot2, and the `%>%` "pipe" operator in R, and is interested in
applying these tools to text data. For users who don't have this
background, we recommend books such as [R for Data
Science](http://r4ds.had.co.nz/). We believe that with a basic
background and interest in tidy data, even a user early in their R
career can understand and apply our examples.

## Using code examples {.unnumbered}

This book was written in [RStudio](http://www.rstudio.com/ide/) using
[bookdown](http://bookdown.org/). The
[website](https://www.tidytextmining.com/) is hosted via
[Netlify](http://netlify.com/), and automatically built after every push
by [GitHub Actions](https://help.github.com/actions). While we show the
code behind the vast majority of the analyses, in the interest of space
we sometimes choose not to show the code generating a particular
visualization if we've already provided the code for several similar
graphs. We trust the reader can learn from and build on our examples,
and the code used to generate the book can be found in our [public
GitHub repository](https://github.com/dgrtwo/tidy-text-mining). We
generated all plots in this book using
[ggplot2](https://ggplot2.tidyverse.org/) and its light theme
(`theme_light()`).

This version of the book was built with `r R.version.string` and the
following packages:

```{r, echo = FALSE, results="asis"}
deps <- desc::desc_get_deps()
pkgs <- sort(deps$package[deps$type == "Imports"])
pkgs <- sessioninfo::package_info(pkgs, dependencies = FALSE)
df <- tibble::tibble(
  package = pkgs$package,
  version = pkgs$ondiskversion,
  source = gsub("@", "\\\\@", pkgs$source)
)
knitr::kable(df, format = "markdown")
```

## Acknowledgements {.unnumbered}

We are deeply grateful for the contributions, support, and perspectives
of individuals and organizations that have helped move this project
forward.

We would like to extend our sincere thanks to Dr. Endang Septiningsih
and Dr. Michael Thomson for hosting us at Texas A&M University. We also
greatly appreciate the support provided by the International Agriculture
Center, National Chung Hsing University, and the Higher Education Sprout
Project, Ministry of Education, Taiwan, for offering opportunities and
partial financial support for this research program.

We are especially thankful for the thoughtful and thorough technical
reviews that significantly enhanced the quality of this work. Finally,
we express our heartfelt gratitude to Mara Averick, Carolyn Clayton,
Simon Jackson, Sean Kross, and Lincoln Mullen for their invaluable
support and encouragement in the lab.
